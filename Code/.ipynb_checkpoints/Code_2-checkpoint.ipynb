{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Two - Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used was the 2017 National Household Travel Survey. This notebook will focus on the cleaning the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import tabula\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../..\")\n",
    "cw = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The National Household Travel Survey has 4 datasets. \n",
    "\n",
    "1. The Person dataset \n",
    "2. The Household dataset\n",
    "3. The Vehicle dataset\n",
    "4. The Travel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import person data\n",
    "data_person=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/perpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks at dimension\n",
    "data_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_person.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_person_obj = data_person.select_dtypes(['object'])\n",
    "print (data_person_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_person[data_person_obj.columns] = data_person_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_person.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import household data\n",
    "data_hh=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/hhpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_hh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_hh_obj = data_hh.select_dtypes(['object'])\n",
    "print (data_hh_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_hh[data_hh_obj.columns] = data_hh_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_hh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import trip data\n",
    "data_trip=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/trippub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_trip_obj = data_trip.select_dtypes(['object'])\n",
    "print (data_trip_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Remove trailing or leading spaces\n",
    "data_trip[data_trip_obj.columns] = data_trip_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dataset info\n",
    "data_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vehicle data\n",
    "data_veh=pd.read_sas(os.path.join(cw,'Capstone_Two_Other_Material/Data/sas/vehpub.sas7bdat'), format = 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first few rows\n",
    "data_veh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_veh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select string variables\n",
    "data_veh_obj = data_veh.select_dtypes(['object'])\n",
    "print (data_veh_obj.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove trailing or leading spaces\n",
    "data_veh[data_veh_obj.columns] = data_veh_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at dimension\n",
    "data_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at data info\n",
    "data_veh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the User Guide documentation provided, many of the variables are repeated across multiple table file levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at similar variables between datasets we want to merge and save them in variables\n",
    "data_hh_columns = set(data_hh.columns)\n",
    "data_veh_columns = set(data_veh.columns)\n",
    "data_person_columns = set(data_person.columns)\n",
    "data_trip_columns = set(data_trip.columns)\n",
    "\n",
    "data_hh_veh_columns = list(data_hh_columns.intersection(data_veh_columns))\n",
    "data_hh_veh_columns_u = list(data_hh_columns.union(data_veh_columns))\n",
    "\n",
    "data_hh_veh_person_columns = list(set(data_hh_veh_columns_u).intersection(data_person_columns))\n",
    "data_hh_veh_person_columns_u = list(set(data_hh_veh_columns_u).union(data_person_columns))\n",
    "\n",
    "data_hh_veh_person_trip_columns = list(set(data_hh_veh_person_columns_u).intersection(data_trip_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge person and vehicle data\n",
    "data_hh_veh = pd.merge(data_hh,data_veh,on=data_hh_veh_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first 5 rows\n",
    "data_hh_veh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data_hh_veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge household and vehicle data to person data\n",
    "data_hh_veh_person = pd.merge(data_hh_veh,data_person,on=data_hh_veh_person_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first 5 rows\n",
    "data_hh_veh_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data_hh_veh_person.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge person, household data, vehicle data to trip data\n",
    "data_hh_veh_person_trip = pd.merge(data_hh_veh_person,data_trip,on=data_hh_veh_person_trip_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review first few rows\n",
    "data_hh_veh_person_trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review dimension\n",
    "data_hh_veh_person_trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the data\n",
    "data = data_hh_veh_person_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nLook at data info\n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reorder variables\n",
    "first_cols = ['PERSONID','VEHID']\n",
    "last_cols = [col for col in data.columns if col not in first_cols]\n",
    "len(last_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder variables\n",
    "data1 = data[first_cols+last_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any duplicate rows?\n",
    "data1 = data1.drop_duplicates()\n",
    "#Dimension\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NAs\n",
    "data1.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NAs in the dataset. The documentation for the dataset mentioned that there shouldn't be any as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few values that should be reviewed further.\n",
    "\n",
    "1. -1 : Appropriate Skip\n",
    "2. -9 : Not Ascertained\n",
    "3. -7 : I prefer not to answer (Selected by participant (available when no answer given)) \n",
    "4. -77 : I prefer not to answer (Selected by participant (always available)) \n",
    "5. -8 : I don’t know (Selected by participant (available when no answer given))\n",
    "6. -88 : I don’t know (Selected by participant (always available))\n",
    "\n",
    "Let's check if any variable consists of all of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables where all values are these\n",
    "data1_check_val = data1.isin([-1.0,-9.0,-7.0,-77.0,-8.0,-88.0, \n",
    "                              '-1','-9','-7','-77','-8','-88']).all()\n",
    "data1_check_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check one variable\n",
    "data1['TRACC_BUS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get variable names\n",
    "var_na = list(data1_check_val[data1_check_val==True].index)\n",
    "var_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of variables\n",
    "len(var_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the variables where everything seems to be not valid.\n",
    "data1.drop(var_na,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get first few rows\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of data\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My intention was the recode the values but since I need them for the next section, I did not recode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a character variables\n",
    "#data1['PHYACT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a numeric variable\n",
    "#data1['PUBTIME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode variables\n",
    "#data1.iloc[:,1:] = data1.iloc[:,1:].replace(dict.fromkeys([-1.0,-9.0,-7.0,-77.0,-8.0,-88.0], np.nan))\n",
    "#data1.iloc[:,1:] = data1.iloc[:,1:].replace(dict.fromkeys(['-1','-9','-7','-77','-8','-88'], np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a character variables\n",
    "#data1['PHYACT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a numeric variable\n",
    "#data1['PUBTIME'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Only Latest Vehicle Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.groupby(['VEHOWNED','VEHOWNMO'])['VEHOWNMO'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VEHOWNED : Owned Vehicle Longer than a Year\n",
    "VEHOWNMO : Months of Vehicle Ownership\n",
    "\n",
    "My intention was to keep the the latest vehicle for each person. What should I do if  a person has multiple vehicles which consists of a Don't Know, Not Ascertained and a vehicle where the time frame is provided? How do I choose the latest vehicle?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['FUELTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 18271/573739 = 3% are using a Hybrid, electric or alternative fuel vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['HFUEL'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my analysis focuses on electric vehicles, we will use the HFUEL variable to distinguish vehicle categories.\n",
    "\n",
    "The value labels for HFUEL is given below.\n",
    "\n",
    "1. -9: Not ascertained\n",
    "2. -8: I don't know\n",
    "3. -1: Appropriate skip\n",
    "4. 01: Biodiesel\n",
    "5. 02: Plug-in Hybrid (gas/electric e.g., Chevy Volt)\n",
    "6. 03: Electric (e.g. Nissan Leaf)\n",
    "7. 04: Hybrid (gas/electric, not plug-in e.g., Toyota Prius)\n",
    "8. 97: Some other fuel\n",
    "\n",
    "I plan to code \"02\" and \"03\" as electric vehicles and the rest as conventional vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Format for Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get these variables\n",
    "#data_1_int =data1[[\"BIKE4EX\",\"BIKESHARE\",\"CARRODE\",\"CARSHARE\",\"CNTTDHH\",\"CNTTDTR\",\"DELIVER\",\"DRVRCNT\",\"HHSIZE\",\"HHVEHCNT\",\"LPACT\",\"MCUSED\",\"NBIKETRP\",\"NUMADLT\",\t\"NUMONTRP\",\t\"NUMTRANS\",\"NWALKTRP\",\"PTUSED\",\"RESP_CNT\",\"RIDESHARE\",\"TRPACCMP\",\"TRPHHACC\",\"VEHYEAR\",\"VPACT\",\"WALK4EX\",\"WKFMHMXX\",\"WRKCOUNT\",\"YOUNGCHILD\",\"YRTOUS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert type\n",
    "#data1[data_1_int.columns]=data_1_int.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info of data\n",
    "#data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first few rows\n",
    "#data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dimension\n",
    "#data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Cells Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 = pd.get_dummies(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waiting to get feedback on the above codes but just trying out this code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating NAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: <br>\n",
    "U.S. Department of Transportation, Federal Highway Administration, 2017 National Household Travel Survey. URL: http://nhts.ornl.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
