{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn import impute\n",
    "\n",
    "from sklearn import model_selection\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from patsy import dmatrix\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "#from scipy.stats import chi2\n",
    "#from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from pyglmnet import GLMCV\n",
    "#from pyglmnet.datasets import fetch_group_lasso_data\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster\n",
    "\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/Avinash/Documents/Kanchanah/Springboard/Data_Science_Track/Capstone_Two_Other_Material/\"\n",
    "\n",
    "X_train = \"Opposite/Data/X_train.csv\"\n",
    "X_test = \"Opposite/Data/X_test.csv\"\n",
    "y_train = \"Opposite/Data/y_train.csv\"\n",
    "y_test = \"Opposite/Data/y_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.expanduser(os.path.join(BASE_DIR, X_train)),index_col=0)\n",
    "X_test = pd.read_csv(os.path.expanduser(os.path.join(BASE_DIR, X_test)),index_col=0)\n",
    "y_train = pd.read_csv(os.path.expanduser(os.path.join(BASE_DIR, y_train)),index_col=0)\n",
    "y_test = pd.read_csv(os.path.expanduser(os.path.join(BASE_DIR, y_test)),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140394 entries, 0 to 140393\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                                         Non-Null Count   Dtype  \n",
      "---  ------                                                         --------------   -----  \n",
      " 0   GT1JBLWK_label_YES                                             140394 non-null  int64  \n",
      " 1   HBHUR_label_RURAL                                              140394 non-null  int64  \n",
      " 2   HHSTATE_label_EAST_SOUTH_CENTRAL                               140394 non-null  int64  \n",
      " 3   HHSTATE_label_MIDDLE_ATLANTIC                                  140394 non-null  int64  \n",
      " 4   HHSTATE_label_MOUNTAIN                                         140394 non-null  int64  \n",
      " 5   HHSTATE_label_NEW_ENGLAND                                      140394 non-null  int64  \n",
      " 6   HHSTATE_label_PACIFIC                                          140394 non-null  int64  \n",
      " 7   HHSTATE_label_SOUTH_ATLANTIC                                   140394 non-null  int64  \n",
      " 8   HHSTATE_label_WEST_NORTH_CENTRAL                               140394 non-null  int64  \n",
      " 9   HHSTATE_label_WEST_SOUTH_CENTRAL                               140394 non-null  int64  \n",
      " 10  HOMEOWN_label_RENT                                             140394 non-null  int64  \n",
      " 11  HOMEOWN_label_SOME_OTHER_ARRANGEMENT                           140394 non-null  int64  \n",
      " 12  OCCAT_label_MANUFACTURING_CONSTRUCTION_MAINTENANCE_OR_FARMING  140394 non-null  int64  \n",
      " 13  OCCAT_label_PROFESSIONAL_MANAGERIAL_OR_TECHNICAL               140394 non-null  int64  \n",
      " 14  OCCAT_label_SALES_OR_SERVICE                                   140394 non-null  int64  \n",
      " 15  OCCAT_label_SOMETHING_ELSE                                     140394 non-null  int64  \n",
      " 16  R_HISP_label_YES_HISPANIC_OR_LATINO                            140394 non-null  int64  \n",
      " 17  R_RACE_label_ASIAN                                             140394 non-null  int64  \n",
      " 18  R_RACE_label_BLACK_OR_AFRICAN_AMERICAN                         140394 non-null  int64  \n",
      " 19  R_RACE_label_DONT_KNOW                                         140394 non-null  int64  \n",
      " 20  R_RACE_label_MULTIPLE_RESPONSES_SELECTED                       140394 non-null  int64  \n",
      " 21  R_RACE_label_NATIVE_HAWAIIAN_OR_OTHER_PACIFIC_ISLANDER         140394 non-null  int64  \n",
      " 22  R_RACE_label_REFUSED                                           140394 non-null  int64  \n",
      " 23  R_RACE_label_SOME_OTHER_RACE                                   140394 non-null  int64  \n",
      " 24  R_RACE_label_WHITE                                             140394 non-null  int64  \n",
      " 25  R_SEX_label_MALE                                               140394 non-null  int64  \n",
      " 26  VEHOWNED_label_YES                                             140394 non-null  int64  \n",
      " 27  WKFTPT_label_PARTTIME                                          140394 non-null  int64  \n",
      " 28  WKRMHM_label_YES                                               140394 non-null  int64  \n",
      " 29  CAR                                                            140394 non-null  float64\n",
      " 30  CARSHARE                                                       140394 non-null  float64\n",
      " 31  DRVRCNT                                                        140394 non-null  float64\n",
      " 32  EDUC                                                           140394 non-null  float64\n",
      " 33  HBPPOPDN                                                       140394 non-null  float64\n",
      " 34  HBRESDN                                                        140394 non-null  float64\n",
      " 35  HHFAMINC                                                       140394 non-null  float64\n",
      " 36  HHSIZE                                                         140394 non-null  float64\n",
      " 37  HHVEHCNT                                                       140394 non-null  float64\n",
      " 38  PLACE                                                          140394 non-null  float64\n",
      " 39  PRICE                                                          140394 non-null  float64\n",
      " 40  R_AGE                                                          140394 non-null  float64\n",
      " 41  TIMETOWK                                                       140394 non-null  float64\n",
      " 42  VEHAGE                                                         140394 non-null  float64\n",
      " 43  VEHOWNMO                                                       140394 non-null  float64\n",
      " 44  WRKCOUNT                                                       140394 non-null  float64\n",
      " 45  YEARMILE                                                       140394 non-null  float64\n",
      " 46  YOUNGCHILD                                                     140394 non-null  float64\n",
      "dtypes: float64(18), int64(29)\n",
      "memory usage: 51.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GT1JBLWK_label_YES</th>\n",
       "      <th>HBHUR_label_RURAL</th>\n",
       "      <th>HHSTATE_label_EAST_SOUTH_CENTRAL</th>\n",
       "      <th>HHSTATE_label_MIDDLE_ATLANTIC</th>\n",
       "      <th>HHSTATE_label_MOUNTAIN</th>\n",
       "      <th>HHSTATE_label_NEW_ENGLAND</th>\n",
       "      <th>HHSTATE_label_PACIFIC</th>\n",
       "      <th>HHSTATE_label_SOUTH_ATLANTIC</th>\n",
       "      <th>HHSTATE_label_WEST_NORTH_CENTRAL</th>\n",
       "      <th>HHSTATE_label_WEST_SOUTH_CENTRAL</th>\n",
       "      <th>...</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>R_AGE</th>\n",
       "      <th>TIMETOWK</th>\n",
       "      <th>VEHAGE</th>\n",
       "      <th>VEHOWNMO</th>\n",
       "      <th>WRKCOUNT</th>\n",
       "      <th>YEARMILE</th>\n",
       "      <th>YOUNGCHILD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GT1JBLWK_label_YES  HBHUR_label_RURAL  HHSTATE_label_EAST_SOUTH_CENTRAL  \\\n",
       "0                   0                  0                                 0   \n",
       "1                   0                  0                                 0   \n",
       "2                   0                  0                                 0   \n",
       "3                   0                  0                                 0   \n",
       "4                   1                  0                                 0   \n",
       "\n",
       "   HHSTATE_label_MIDDLE_ATLANTIC  HHSTATE_label_MOUNTAIN  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "\n",
       "   HHSTATE_label_NEW_ENGLAND  HHSTATE_label_PACIFIC  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "\n",
       "   HHSTATE_label_SOUTH_ATLANTIC  HHSTATE_label_WEST_NORTH_CENTRAL  \\\n",
       "0                             0                                 0   \n",
       "1                             1                                 0   \n",
       "2                             0                                 0   \n",
       "3                             0                                 0   \n",
       "4                             1                                 0   \n",
       "\n",
       "   HHSTATE_label_WEST_SOUTH_CENTRAL  ...  HHVEHCNT  PLACE  PRICE     R_AGE  \\\n",
       "0                                 0  ...  0.090909   0.50   0.50  0.609195   \n",
       "1                                 0  ...  0.090909   0.25   0.25  0.609195   \n",
       "2                                 0  ...  0.090909   0.75   1.00  0.666667   \n",
       "3                                 1  ...  0.000000   0.50   0.50  0.781609   \n",
       "4                                 0  ...  0.090909   0.00   0.00  0.344828   \n",
       "\n",
       "   TIMETOWK    VEHAGE  VEHOWNMO  WRKCOUNT  YEARMILE  YOUNGCHILD  \n",
       "0  0.033333  0.000000  0.454545  0.142857     0.050         0.0  \n",
       "1  0.033333  0.153846  0.454545  0.142857     0.050         0.0  \n",
       "2  0.033333  0.000000  0.454545  0.000000     0.050         0.0  \n",
       "3  0.033333  0.230769  0.454545  0.000000     0.005         0.0  \n",
       "4  0.100000  0.333333  0.363636  0.285714     0.050         0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140394, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60170 entries, 0 to 60169\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                                         Non-Null Count  Dtype  \n",
      "---  ------                                                         --------------  -----  \n",
      " 0   GT1JBLWK_label_YES                                             60170 non-null  int64  \n",
      " 1   HBHUR_label_RURAL                                              60170 non-null  int64  \n",
      " 2   HHSTATE_label_EAST_SOUTH_CENTRAL                               60170 non-null  int64  \n",
      " 3   HHSTATE_label_MIDDLE_ATLANTIC                                  60170 non-null  int64  \n",
      " 4   HHSTATE_label_MOUNTAIN                                         60170 non-null  int64  \n",
      " 5   HHSTATE_label_NEW_ENGLAND                                      60170 non-null  int64  \n",
      " 6   HHSTATE_label_PACIFIC                                          60170 non-null  int64  \n",
      " 7   HHSTATE_label_SOUTH_ATLANTIC                                   60170 non-null  int64  \n",
      " 8   HHSTATE_label_WEST_NORTH_CENTRAL                               60170 non-null  int64  \n",
      " 9   HHSTATE_label_WEST_SOUTH_CENTRAL                               60170 non-null  int64  \n",
      " 10  HOMEOWN_label_RENT                                             60170 non-null  int64  \n",
      " 11  HOMEOWN_label_SOME_OTHER_ARRANGEMENT                           60170 non-null  int64  \n",
      " 12  OCCAT_label_MANUFACTURING_CONSTRUCTION_MAINTENANCE_OR_FARMING  60170 non-null  int64  \n",
      " 13  OCCAT_label_PROFESSIONAL_MANAGERIAL_OR_TECHNICAL               60170 non-null  int64  \n",
      " 14  OCCAT_label_SALES_OR_SERVICE                                   60170 non-null  int64  \n",
      " 15  OCCAT_label_SOMETHING_ELSE                                     60170 non-null  int64  \n",
      " 16  R_HISP_label_YES_HISPANIC_OR_LATINO                            60170 non-null  int64  \n",
      " 17  R_RACE_label_ASIAN                                             60170 non-null  int64  \n",
      " 18  R_RACE_label_BLACK_OR_AFRICAN_AMERICAN                         60170 non-null  int64  \n",
      " 19  R_RACE_label_DONT_KNOW                                         60170 non-null  int64  \n",
      " 20  R_RACE_label_MULTIPLE_RESPONSES_SELECTED                       60170 non-null  int64  \n",
      " 21  R_RACE_label_NATIVE_HAWAIIAN_OR_OTHER_PACIFIC_ISLANDER         60170 non-null  int64  \n",
      " 22  R_RACE_label_REFUSED                                           60170 non-null  int64  \n",
      " 23  R_RACE_label_SOME_OTHER_RACE                                   60170 non-null  int64  \n",
      " 24  R_RACE_label_WHITE                                             60170 non-null  int64  \n",
      " 25  R_SEX_label_MALE                                               60170 non-null  int64  \n",
      " 26  VEHOWNED_label_YES                                             60170 non-null  int64  \n",
      " 27  WKFTPT_label_PARTTIME                                          60170 non-null  int64  \n",
      " 28  WKRMHM_label_YES                                               60170 non-null  int64  \n",
      " 29  CAR                                                            60170 non-null  float64\n",
      " 30  CARSHARE                                                       60170 non-null  float64\n",
      " 31  DRVRCNT                                                        60170 non-null  float64\n",
      " 32  EDUC                                                           60170 non-null  float64\n",
      " 33  HBPPOPDN                                                       60170 non-null  float64\n",
      " 34  HBRESDN                                                        60170 non-null  float64\n",
      " 35  HHFAMINC                                                       60170 non-null  float64\n",
      " 36  HHSIZE                                                         60170 non-null  float64\n",
      " 37  HHVEHCNT                                                       60170 non-null  float64\n",
      " 38  PLACE                                                          60170 non-null  float64\n",
      " 39  PRICE                                                          60170 non-null  float64\n",
      " 40  R_AGE                                                          60170 non-null  float64\n",
      " 41  TIMETOWK                                                       60170 non-null  float64\n",
      " 42  VEHAGE                                                         60170 non-null  float64\n",
      " 43  VEHOWNMO                                                       60170 non-null  float64\n",
      " 44  WRKCOUNT                                                       60170 non-null  float64\n",
      " 45  YEARMILE                                                       60170 non-null  float64\n",
      " 46  YOUNGCHILD                                                     60170 non-null  float64\n",
      "dtypes: float64(18), int64(29)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GT1JBLWK_label_YES</th>\n",
       "      <th>HBHUR_label_RURAL</th>\n",
       "      <th>HHSTATE_label_EAST_SOUTH_CENTRAL</th>\n",
       "      <th>HHSTATE_label_MIDDLE_ATLANTIC</th>\n",
       "      <th>HHSTATE_label_MOUNTAIN</th>\n",
       "      <th>HHSTATE_label_NEW_ENGLAND</th>\n",
       "      <th>HHSTATE_label_PACIFIC</th>\n",
       "      <th>HHSTATE_label_SOUTH_ATLANTIC</th>\n",
       "      <th>HHSTATE_label_WEST_NORTH_CENTRAL</th>\n",
       "      <th>HHSTATE_label_WEST_SOUTH_CENTRAL</th>\n",
       "      <th>...</th>\n",
       "      <th>HHVEHCNT</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>R_AGE</th>\n",
       "      <th>TIMETOWK</th>\n",
       "      <th>VEHAGE</th>\n",
       "      <th>VEHOWNMO</th>\n",
       "      <th>WRKCOUNT</th>\n",
       "      <th>YEARMILE</th>\n",
       "      <th>YOUNGCHILD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GT1JBLWK_label_YES  HBHUR_label_RURAL  HHSTATE_label_EAST_SOUTH_CENTRAL  \\\n",
       "0                   0                  0                                 0   \n",
       "1                   0                  1                                 0   \n",
       "2                   0                  0                                 0   \n",
       "3                   0                  0                                 0   \n",
       "4                   0                  0                                 0   \n",
       "\n",
       "   HHSTATE_label_MIDDLE_ATLANTIC  HHSTATE_label_MOUNTAIN  \\\n",
       "0                              0                       1   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "\n",
       "   HHSTATE_label_NEW_ENGLAND  HHSTATE_label_PACIFIC  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      1   \n",
       "4                          0                      0   \n",
       "\n",
       "   HHSTATE_label_SOUTH_ATLANTIC  HHSTATE_label_WEST_NORTH_CENTRAL  \\\n",
       "0                             0                                 0   \n",
       "1                             0                                 1   \n",
       "2                             0                                 1   \n",
       "3                             0                                 0   \n",
       "4                             0                                 0   \n",
       "\n",
       "   HHSTATE_label_WEST_SOUTH_CENTRAL  ...  HHVEHCNT  PLACE  PRICE     R_AGE  \\\n",
       "0                                 0  ...  0.181818   0.25   0.25  0.252874   \n",
       "1                                 0  ...  0.181818   0.50   0.50  0.689655   \n",
       "2                                 0  ...  0.000000   1.00   0.25  0.310345   \n",
       "3                                 0  ...  0.090909   0.50   0.25  0.724138   \n",
       "4                                 1  ...  0.090909   0.00   0.00  0.356322   \n",
       "\n",
       "   TIMETOWK    VEHAGE  VEHOWNMO  WRKCOUNT  YEARMILE  YOUNGCHILD  \n",
       "0  0.025000  0.076923  0.454545  0.285714     0.065         0.0  \n",
       "1  0.033333  0.076923  0.363636  0.000000     0.015         0.0  \n",
       "2  0.033333  0.384615  0.909091  0.142857     0.050         0.2  \n",
       "3  0.075000  0.410256  0.454545  0.285714     0.025         0.0  \n",
       "4  0.025000  0.025641  0.454545  0.142857     0.090         0.4  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60170, 47)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fueltype_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fueltype_numeric\n",
       "0                 1\n",
       "1                 1\n",
       "2                 1\n",
       "3                 1\n",
       "4                 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9a54a0814dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcull_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/displayhook.py\u001b[0m in \u001b[0;36mfinish_displayhook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\"Finish up all displayhook activities.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create threshold and visualize\n",
    "\n",
    "n_points=50\n",
    "probs = np.linspace(0, 1, n_points)\n",
    "\n",
    "def threshold_and_plot(y_test, target, plot=True):\n",
    "\n",
    "    def make_thresh():  # try n_points = 50 or 100...\n",
    "    # calculate each metric here\n",
    "        precision = [\n",
    "        metrics.precision_score(y_test, np.where(target > thresh, 1, 0))\n",
    "        for thresh in probs]\n",
    "        recall = [metrics.recall_score(y_test, np.where(target > thresh, 1, 0))\n",
    "              for thresh in probs]\n",
    "        f1 = [metrics.f1_score(y_test, np.where(target > thresh, 1, 0))\n",
    "          for thresh in probs]\n",
    "        return precision, recall, f1\n",
    "\n",
    "    precision, recall, f1 = make_thresh()\n",
    "    if plot:\n",
    "        plt.plot(probs, precision, label='precision')\n",
    "        plt.plot(probs, recall, label='recall')\n",
    "        plt.plot(probs, f1, label='f1')\n",
    "        plt.title(\"Metrics at various thresholds\");\n",
    "        plt.xlabel(\"Probability\");\n",
    "        plt.ylabel(\"Metric value\")\n",
    "        plt.legend();\n",
    "    # print(\"Precision: {:.3f}; Recall: {:.3f}; F1: {:.3f}\".format(precision, recall, f1))\n",
    "        return precision, recall, f1\n",
    "    else:\n",
    "        return precision, recall, f1\n",
    "\n",
    "\n",
    "def max_thresh(score_vec):\n",
    "    max_idx = np.argmax(score_vec)\n",
    "    max_score = score_vec[max_idx]\n",
    "    return max_idx, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cross-validator:\n",
    "# 80/20 train/calibration split in this data (test data still held out)\n",
    "# 200 iterations\n",
    "# feel free to use another CV method and explain why\n",
    "cross_validator = (\n",
    "  model_selection.StratifiedShuffleSplit(train_size=0.8,\n",
    "                                         random_state=1337,\n",
    "                                         n_splits=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null model boilerplate\n",
    "null_reg = LogisticRegression(fit_intercept=False,\n",
    "                                           max_iter=500,\n",
    "                                           random_state=632966)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_null = np.ones(shape=y_train.shape[0]).reshape(-1,1) # intercept\n",
    "X_test_null = np.ones(shape=y_test.shape[0]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on train and test data (no tuning)\n",
    "null_train = null_reg.fit(X=X_train_null, y=y_train.values.ravel())\n",
    "null_test = null_reg.fit(X=X_test_null, y=y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_a (and prob) gives you two columns; second one is the target\n",
    "#why do we fit with the test here?\n",
    "train_pred = null_train.predict_proba(X_train_null)\n",
    "test_pred = null_test.predict_proba(X_test_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if close to population value\n",
    "print(f\"Observed: {y_train.values.ravel().mean():.3f} Fit: {train_pred[:,1].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 values of C to search over (can use fewer to speed things up);\n",
    "# would need to amend to use L2 or elastic net\n",
    "model_params = {\"model__C\": (np.logspace(start=-4, stop=4, num=20))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline: just contains the model object\n",
    "model_pipeline = Pipeline(steps=[(\"model\", null_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grid search\n",
    "model_grid = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"roc_auc\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "null_model = model_grid.fit(X_train_null, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "null_train_pred = null_model.predict_proba(X_train_null)\n",
    "null_test_pred = null_model.predict_proba(X_test_null)\n",
    "\n",
    "# check to see if close to population value\n",
    "print(f\"Observed: {y_train.values.ravel().mean():.3f} Fit: {null_train_pred[:,1].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: null F1\n",
    "train_null = null_model.predict(X_train_null)\n",
    "test_null = null_model.predict(X_test_null)\n",
    "\n",
    "\n",
    "null_train_f1 = metrics.f1_score(y_true=y_train, y_pred=train_null, average=\"weighted\")\n",
    "null_test_f1 = metrics.f1_score(y_true=y_test, y_pred=test_null, average=\"weighted\")\n",
    "\n",
    "print(f\"Train null F1: {null_train_f1:.3}\")\n",
    "print(f\"Test null F1: {null_test_f1:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to Numeric Variabes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: numeric only values\n",
    "X_train_numeric = X_train.iloc[:, 29:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null model boilerplate\n",
    "log_reg = LogisticRegression(fit_intercept=True, random_state=632966,\n",
    "                             class_weight='balanced', penalty=\"elasticnet\",\n",
    "                             solver=\"saga\", max_iter=500)\n",
    "\n",
    "#30 values of C to search over (can use fewer to speed things up);\n",
    "#would need to amend to use L2 or elastic net\n",
    "model_params = {\"model__C\": (np.logspace(start=-4, stop=4, num=4)),\n",
    "                \"model__l1_ratio\": np.linspace(0., 1., num=4)}\n",
    "\n",
    "# set up the pipeline: just contains the model object\n",
    "model_pipeline = Pipeline(steps=[(\"model\", log_reg)])\n",
    "\n",
    "cross_validator = (\n",
    "  model_selection.StratifiedShuffleSplit(train_size=0.8,\n",
    "                                         random_state=1337,\n",
    "                                         n_splits=10))\n",
    "\n",
    "# set up grid search\n",
    "# TODO: ue f-beta\n",
    "model_grid = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"f1_weighted\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit model\n",
    "log_model = model_grid.fit(X_train_numeric, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW best params\n",
    "log_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: best estimator fit\n",
    "#Question: Why use best_estimator?? - should be the optimal parameter\n",
    "log_best_train = log_model.best_estimator_.fit(X_train_numeric, y_train.values.ravel())\n",
    "log_best_train_pred = log_model.best_estimator_.predict_proba(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# NEW: cross-val uncertainty\n",
    "# TODO: check for convergence\n",
    "log_reg_cv_scores = (\n",
    "    model_selection.cross_val_score(log_model.best_estimator_,\n",
    "                                    X_train_numeric,\n",
    "                                    y_train.to_numpy().ravel(),\n",
    "                                    scoring=\"roc_auc\",\n",
    "                                    cv=cross_validator,\n",
    "                                    n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.histplot(log_reg_cv_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: check shape\n",
    "log_best_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: vectors of metrics\n",
    "# TODO: add weighting to them (source function)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "log_reg_pr, log_reg_rec, log_reg_f1 = threshold_and_plot(y_train, log_best_train_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: F1 thresh\n",
    "max_thresh(log_reg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: threshold that maizmizes value\n",
    "log_reg_f1_preds = np.where(log_best_train_pred[:,1] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: confusion matrix\n",
    "\n",
    "# no normalization\n",
    "metrics.ConfusionMatrixDisplay.from_predictions(y_true=y_train, y_pred=log_reg_f1_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: ROC AUC\n",
    "metrics.RocCurveDisplay.from_predictions(y_true=y_train, y_pred=log_reg_f1_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: PR AUC\n",
    "metrics.PrecisionRecallDisplay.from_predictions(y_true=y_train, y_pred=log_reg_f1_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW: Matthews correlation\n",
    "metrics.matthews_corrcoef(y_true=y_train, y_pred=log_reg_f1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW : prediction DataFrame\n",
    "log_reg_pred_df = pd.DataFrame({\"targets\": y_train.values.ravel(),\n",
    "                                \"preds\": log_best_train_pred[:,1]})\n",
    "\n",
    "log_reg_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "sns.histplot(data=log_reg_pred_df, x=\"preds\", hue=\"targets\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "log_train_pred = log_model.predict_proba(X_train_numeric)\n",
    "log_test_pred = log_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if close to population value\n",
    "print(f\"Observed: {y_train.values.ravel().mean():.3f} Fit: {np.mean(log_train_pred[:,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric = threshold_and_plot(y_test=y_train, target=log_train_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx_c = []\n",
    "# print out the maximum value\n",
    "# assumes that \"test_metrics\" is a tuple to be unpacked\n",
    "for metric, val in zip([\"Precision\", \"Recall\", \"F1\"], test_metric):\n",
    "    max_idx, max_val = max_thresh(val)\n",
    "    val = np.linspace(0, 1, 50)[max_idx]\n",
    "    max_idx_c.append(val)\n",
    "    print(f\"Maximum {metric}:{max_val:.3f} and id:{np.linspace(0, 1, 50)[max_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Evaluate on the test data\n",
    "\n",
    "print(\"Precision on Test: {0}\".format(metrics.precision_score(y_test, np.where(log_test_pred[:,1] > max_idx_c[0], 1, 0))))\n",
    "print(\"Recall on Test: {0}\".format(metrics.recall_score(y_test, np.where(log_test_pred[:,1] > max_idx_c[1], 1, 0))))\n",
    "print(\"F1 score on Test: {0}\".format(metrics.f1_score(y_test, np.where(log_test_pred[:,1] > max_idx_c[2], 1, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "pos_reg = linear_model.PoissonRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 values of C to search over (can use fewer to speed things up);\n",
    "# would need to amend to use L2 or elastic net\n",
    "model_params = {\"model__alpha\": (np.linspace(0.0,1,20))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline: just contains the model object\n",
    "model_pipeline = Pipeline(steps=[('model', pos_reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grid search\n",
    "model_grid_pos = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"f1_weighted\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "pos_model = model_grid_pos.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "pos_train_pred = pos_model.predict(X_train)\n",
    "pos_test_pred = pos_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check to see if close to population value\n",
    "print(f\"Observed: {y_train.values.ravel().mean():.3f} Fit: {np.mean(pos_train_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric_pos = threshold_and_plot(y_test=y_train, target=pos_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx_c = []\n",
    "# print out the maximum value\n",
    "# assumes that \"test_metrics\" is a tuple to be unpacked\n",
    "for metric, val in zip([\"Precision\", \"Recall\", \"F1\"], test_metric_pos):\n",
    "    max_idx, max_val = max_thresh(val)\n",
    "    val = np.linspace(0, 1, 50)[max_idx]\n",
    "    max_idx_c.append(val)\n",
    "    print(f\"Maximum {metric}:{max_val:.3f} and id:{np.linspace(0, 1, 50)[max_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Evaluate on the test data\n",
    "\n",
    "print(\"Precision on Test: {0}\".format(metrics.precision_score(y_test, np.where(pos_test_pred> max_idx_c[0], 1, 0))))\n",
    "print(\"Recall on Test: {0}\".format(metrics.recall_score(y_test, np.where(pos_test_pred > max_idx_c[1], 1, 0))))\n",
    "print(\"F1 score on Test: {0}\".format(metrics.f1_score(y_test, np.where(pos_test_pred > max_idx_c[2], 1, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 values of C to search over (can use fewer to speed things up);\n",
    "# would need to amend to use L2 or elastic net\n",
    "model_params = {'model__n_estimators': [100, 200],\n",
    "    'model__max_features': ['auto', 'sqrt'],\n",
    "    'model__max_depth' : [4, 5, 6],\n",
    "    'model__criterion' :['gini']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline: just contains the model object\n",
    "model_pipeline = Pipeline(steps=[('model', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grid search\n",
    "model_grid_rfc = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"f1_weighted\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "rfc_model = model_grid_rfc.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "rfc_train_pred = rfc_model.predict_proba(X_train)\n",
    "rfc_test_pred = rfc_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check to see if close to population value\n",
    "print(f\"Observed: {y_train.values.ravel().mean():.3f} Fit: {np.mean(rfc_train_pred[:,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric_rfc = threshold_and_plot(y_test=y_train, target=rfc_train_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx_c = []\n",
    "# print out the maximum value\n",
    "# assumes that \"test_metrics\" is a tuple to be unpacked\n",
    "for metric, val in zip([\"Precision\", \"Recall\", \"F1\"], test_metric_rfc):\n",
    "    max_idx, max_val = max_thresh(val)\n",
    "    val = np.linspace(0, 1, 50)[max_idx]\n",
    "    max_idx_c.append(val)\n",
    "    print(f\"Maximum {metric}:{max_val:.3f} and id:{np.linspace(0, 1, 50)[max_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Evaluate on the test data\n",
    "\n",
    "print(\"Precision on Test: {0}\".format(metrics.precision_score(y_test, np.where(rfc_test_pred[:,1] > max_idx_c[0], 1, 0))))\n",
    "print(\"Recall on Test: {0}\".format(metrics.recall_score(y_test, np.where(rfc_test_pred[:,1] > max_idx_c[1], 1, 0))))\n",
    "print(\"F1 score on Test: {0}\".format(metrics.f1_score(y_test, np.where(rfc_test_pred[:,1] > max_idx_c[2], 1, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW: numeric variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit AdaBoost model\n",
    "ada_def = ensemble.AdaBoostClassifier(n_estimators=150,\n",
    "                                      random_state=2021)\n",
    "ada_model = ada_def.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit gradient boosting model\n",
    "gb_def = ensemble.GradientBoostingClassifier(n_estimators=150,\n",
    "                                             loss=\"deviance\",\n",
    "                                             max_features=\"sqrt\",\n",
    "                                             random_state=2021)\n",
    "gb_model = gb_def.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variable importance\n",
    "ada_rel_importance = ada_model.feature_importances_\n",
    "gb_rel_importance = gb_model.feature_importances_\n",
    "\n",
    "# TODO: determine correct amount to take\n",
    "# ADA\n",
    "ada_feature_importance = 100.0 * (ada_rel_importance / ada_rel_importance.max())\n",
    "ada_sorted_idx = np.argsort(ada_feature_importance)\n",
    "ada_sorted_cols = X_train.columns.values[ada_sorted_idx]\n",
    "\n",
    "# GB\n",
    "gb_feature_importance = 100.0 * (gb_rel_importance / gb_rel_importance.max())\n",
    "gb_sorted_idx = np.argsort(gb_feature_importance)\n",
    "gb_sorted_cols = X_train.columns.values[gb_sorted_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.arange(ada_sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, ada_feature_importance[ada_sorted_idx], align='center')\n",
    "plt.yticks(pos, ada_sorted_cols)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance - Ada boost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.arange(gb_sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, gb_feature_importance[gb_sorted_idx], align='center')\n",
    "plt.yticks(pos, gb_sorted_cols)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance - Gradient boost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_sorted_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_fmla = \"HHSTATE_label_PACIFIC * EDUC * HHFAMINC * R_AGE * PLACE * PRICE - 1\"\n",
    "X_train_import = dmatrix(impt_fmla, X_train)\n",
    "X_train_names = X_train_import.design_info.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW: Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel=\"linear\", gamma=\"scale\", shrinking=True,\n",
    "              probability=True, class_weight=\"balanced\",\n",
    "              random_state=1337)\n",
    "\n",
    "# model_params = {\"model__C\": (np.logspace(start=-4, stop=4, num=10))}\n",
    "model_params = {\"model__C\": [1.]}\n",
    "\n",
    "model_pipeline = Pipeline(steps=[(\"model\", svc)])\n",
    "\n",
    "cross_validator = (\n",
    "  model_selection.StratifiedShuffleSplit(train_size=0.8,\n",
    "                                         random_state=1337,\n",
    "                                         n_splits=10))\n",
    "\n",
    "# set up grid search\n",
    "# TODO: ue f-beta\n",
    "model_grid = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"f1_weighted\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc_model = model_grid.fit(X_train_numeric, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hing loss = linear SVM\n",
    "sgd = linear_model.SGDClassifier(loss=\"modified_huber\", penalty=\"l2\",\n",
    "                                 fit_intercept=True, n_jobs=-1,\n",
    "                                 random_state=1337, eta0=1e-3,\n",
    "                                 validation_fraction=0.2)\n",
    "\n",
    "\n",
    "model_params = {\"model__alpha\": np.linspace(-3., 3., 10)}\n",
    "\n",
    "model_pipeline = Pipeline(steps=[(\"model\", sgd)])\n",
    "\n",
    "cross_validator = (\n",
    "  model_selection.StratifiedShuffleSplit(train_size=0.8,\n",
    "                                         random_state=1337,\n",
    "                                         n_splits=10))\n",
    "\n",
    "# set up grid search\n",
    "# TODO: ue f-beta\n",
    "model_grid = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=True, # refit using best estimates\n",
    "                               scoring=\"roc_auc\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_model = sgd.partial_fit(np.array(X_train_import), y_train.values.ravel(), np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_best_train_pred = sgd_model.predict_proba(np.array(X_train_import))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_cv_scores = (\n",
    "    model_selection.cross_val_score(sgd_model,\n",
    "                                    np.array(X_train_import),\n",
    "                                    y_train.to_numpy().ravel(),\n",
    "                                    scoring=\"roc_auc\",\n",
    "                                    cv=cross_validator,\n",
    "                                    n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.histplot(sgd_cv_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sgd_pr, sgd_rec, sgd_f1 = threshold_and_plot(y_train, sgd_best_train_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_thresh(sgd_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_f1_preds = np.where(sgd_best_train_pred[:,1] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(y_true=y_train, y_pred=sgd_f1_preds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pred_df = pd.DataFrame({\"targets\": y_train.values.ravel(),\n",
    "                            \"preds\": sgd_best_train_pred[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "sns.histplot(data=sgd_pred_df, x=\"preds\", hue=\"targets\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW: DNN (why not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# calbacks/checkpoints\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# regularization, initializers, optimizers, activations, losses\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics as tf_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch monitoring\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < int(epoch * 0.75):\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "def callbacks():\n",
    "  early_stop = EarlyStopping(monitor=\"loss\", patience=30,\n",
    "                             mode=\"min\", min_delta=0.01)\n",
    "  lr_schedule = LearningRateScheduler(scheduler)\n",
    "  lr_plateau = ReduceLROnPlateau(monitor=\"loss\", factor=0.8, patience=30)\n",
    "  return (early_stop, lr_schedule, lr_plateau)\n",
    "\n",
    "early_stop, lr_schedule, lr_plateau = callbacks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new nn def'n with important variables\n",
    "\n",
    "def logistic_impt_model(n_features):\n",
    "  # input layer: (batch_size, features); batch_size implied\n",
    "  input_layer = Dense(units=18,\n",
    "                      input_shape=(n_features,),\n",
    "                      activation=\"elu\",\n",
    "                      name=\"input\")\n",
    "  hidden_1 = Dense(units=18, activation=\"elu\", name=\"hidden_1\")\n",
    "  drop_1 = Dropout(rate=0.1, name=\"dropout_1\")\n",
    "  hidden_2 = Dense(units=16, activation=\"elu\", name=\"hidden_2\")\n",
    "  drop_2 = Dropout(rate=0.5, name=\"dropout_2\")\n",
    "  hidden_3 = Dense(units=8, activation=\"elu\", name=\"hidden_3\")\n",
    "  hidden_4 = Dense(units=8, activation=\"elu\", name=\"hidden_4\")\n",
    "  hidden_5 = Dense(units=4, activation=\"elu\", name=\"hidden_5\")\n",
    "  hidden_6 = Dense(units=2, activation=\"elu\", name=\"hidden_6\")\n",
    "  output_layer = Dense(units=1, name=\"output\", activation=\"sigmoid\")\n",
    "\n",
    "  # build model\n",
    "  model = Sequential(name=\"logistic_model\")\n",
    "  model.add(input_layer)\n",
    "  model.add(hidden_1)\n",
    "  model.add(drop_1)\n",
    "  model.add(hidden_2)\n",
    "  model.add(drop_2)\n",
    "  model.add(hidden_3)\n",
    "  model.add(hidden_4)\n",
    "  model.add(hidden_5)\n",
    "  model.add(hidden_6)\n",
    "  model.add(output_layer)\n",
    "\n",
    "  # compilation; learning rate set by scheduler\n",
    "\n",
    "  model.compile(optimizer=optimizers.SGD(momentum=0.9,\n",
    "                                         nesterov=True),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[tf_metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "                         tf_metrics.Precision(name=\"precision\"),\n",
    "                         tf_metrics.Recall(name=\"recall\"),\n",
    "                         tf_metrics.AUC(name=\"auc\"),\n",
    "                         tf_metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "                         #tf_metrics.TrueNegatives(name=\"true_neg\"),\n",
    "                         #tf_metrics.TruePositives(name=\"true_pos\"),\n",
    "                         #tf_metrics.FalseNegatives(name=\"false_neg\"),\n",
    "                         #tf_metrics.FalsePositives(name=\"false_pos\"),\n",
    "                         ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_nn = logistic_impt_model(46)\n",
    "logistic_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see test predictions w/o training\n",
    "untrained_test = logistic_nn.predict(X_test)\n",
    "tf.reduce_mean(untrained_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** np.linspace(0, 12, num=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduce = X_train.drop(\"VEHAGE\",axis=1)\n",
    "X_train_reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model\n",
    "\n",
    "early_stop, lr_schedule, lr_plateau = callbacks()\n",
    "\n",
    "nn_impt_history = logistic_nn.fit(x=X_train_reduce,\n",
    "                                  y=y_train.values.ravel(),\n",
    "                                  validation_split=0.2,\n",
    "                                  epochs=10_000,\n",
    "                                  callbacks=[early_stop, lr_schedule, lr_plateau],\n",
    "                                  batch_size=4096,\n",
    "                                  verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_impt_df = pd.DataFrame(nn_impt_history.history)\n",
    "\n",
    "loss_impt_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "epochs = np.arange(loss_impt_df.shape[0])\n",
    "\n",
    "# Loss plot\n",
    "ax = fig.add_subplot(221)\n",
    "ax.plot(epochs, loss_impt_df['loss'], label=\"Train\")\n",
    "ax.plot(epochs, loss_impt_df['val_loss'], label=\"Validation\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Loss vs Epochs\")\n",
    "ax.legend();\n",
    "\n",
    "# Accuracy plot\n",
    "ax = fig.add_subplot(222)\n",
    "ax.plot(epochs, loss_impt_df['accuracy'], label=\"Train\")\n",
    "ax.plot(epochs, loss_impt_df['val_accuracy'], label=\"Validation\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy vs Epochs\")\n",
    "ax.legend();\n",
    "\n",
    "# precision plot\n",
    "ax = fig.add_subplot(223)\n",
    "ax.plot(epochs, loss_impt_df['precision'], label=\"Train\")\n",
    "ax.plot(epochs, loss_impt_df['val_precision'], label=\"Validation\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"Precision vs Epochs\")\n",
    "ax.legend();\n",
    "\n",
    "# recall plot\n",
    "ax = fig.add_subplot(224)\n",
    "ax.plot(epochs, loss_impt_df['recall'], label=\"Train\")\n",
    "ax.plot(epochs, loss_impt_df['val_recall'], label=\"Validation\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Recall\")\n",
    "ax.set_title(\"Recall vs Epochs\")\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_nn_impt_trained_predict = logistic_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make binary values(use convention)\n",
    "logistic_nn_impt_label = np.where(logistic_nn_impt_trained_predict > 0.5, 1., 0.)\n",
    "\n",
    "# check confusion matrix\n",
    "logistic_impt_conf_mtx = (\n",
    "    metrics.confusion_matrix(y_true=y_test.values.ravel(), y_pred=logistic_nn_impt_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logistic_impt_conf_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW: one-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hing loss = linear SVM\n",
    "oc_svm = svm.OneClassSVM(kernel=\"rbf\", gamma=\"scale\",\n",
    "                         tol=0.05)\n",
    "\n",
    "model_pipeline = Pipeline(steps=[(\"model\", oc_svm)])\n",
    "\n",
    "cross_validator = (\n",
    "  model_selection.StratifiedShuffleSplit(train_size=0.8,\n",
    "                                         random_state=1337,\n",
    "                                         n_splits=10))\n",
    "\n",
    "# set up grid search\n",
    "# TODO: ue f-beta\n",
    "model_grid = (GridSearchCV(estimator=model_pipeline,\n",
    "                               param_grid=model_params,\n",
    "                               refit=False, # no searching here\n",
    "                               scoring=\"roc_auc\", # metric to optimize\n",
    "                               cv=cross_validator,\n",
    "                               n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample for testing\n",
    "X_train_sample = X_train.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oc_svm_model = oc_svm.fit(X_train_sample, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predictions\n",
    "oc_svm_test_pred = oc_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(oc_svm_test_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = cluster.KMeans(n_clusters=2, # EV/non-EV (in theory)\n",
    "                                       init=\"k-means++\",\n",
    "                                       max_iter=1000,\n",
    "                                       random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "k_means_fit = k_means.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_fit.predict(X_train_numeric).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cluster_id =k_means_fit.predict(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_predict = pd.DataFrame({\"kmeans_cluster_id\": kmeans_cluster_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cf_matrix = metrics.confusion_matrix(y_train,kmeans_cluster_id, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(kmeans_cf_matrix, annot=True, fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Mini-Batch K-means Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['EV','Non-EV'])\n",
    "ax.yaxis.set_ticklabels(['EV','Non-EV'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_k = cluster.MiniBatchKMeans(n_clusters=2, # EV/non-EV (in theory)\n",
    "                                       init=\"k-means++\",\n",
    "                                       max_iter=500,\n",
    "                                       batch_size=4096,\n",
    "                                       random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mini_batch_fit = mini_batch_k.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_fit.predict(X_train_numeric).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_cluster_id = mini_batch_fit.predict(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_predict = pd.DataFrame({\"mini_batch_cluster_id\": mini_batch_cluster_id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_cf_matrix = metrics.confusion_matrix(y_train,mini_batch_cluster_id, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mini_batch_cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(mini_batch_cf_matrix, annot=True, fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Mini-Batch K-means Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['EV','Non-EV'])\n",
    "ax.yaxis.set_ticklabels(['EV','Non-EV'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions seem better than the values we received throught supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare For Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans= pd.concat([X_train_numeric, kmeans_predict,y_train], axis=1)\n",
    "X_train_labeled_mini= pd.concat([X_train_numeric, mini_batch_predict,y_train], axis=1)\n",
    "\n",
    "X_train_labeled_kmeans['type'] = 'Kmeans'\n",
    "X_train_labeled_mini['type'] = 'Mini-Batch'\n",
    "\n",
    "#X_train_labeled_kmeans_mini.rename(columns={'fueltype_numeric':'y_train'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans.rename(columns = {'kmeans_cluster_id':'predict'}, inplace=True)\n",
    "X_train_labeled_mini.rename(columns = {'mini_batch_cluster_id':'predict'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini = pd.concat([X_train_labeled_kmeans, X_train_labeled_mini], axis=0)\n",
    "X_train_labeled_kmeans_mini.rename(columns = {'fueltype_numeric':'y_train'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read min-max file\n",
    "\n",
    "#os.getcwd()\n",
    "\n",
    "min_max = pd.read_csv(\"/Users/Avinash/Documents/Kanchanah/Springboard/Data_Science_Track/Capstone_Two_Other_Material/Opposite/min_max.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove last three columns\n",
    "X_train_labeled_kmeans_mini_sub = X_train_labeled_kmeans_mini.iloc[:,0:(X_train_labeled_kmeans_mini.shape[1]-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate original values\n",
    "X_train_labeled_kmeans_mini_ori = np.multiply(X_train_labeled_kmeans_mini_sub,(min_max.iloc[1,:].to_numpy() - min_max.iloc[0,:].to_numpy())) + min_max.iloc[0,:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read codebook file to apply labels for categorical variables\n",
    "\n",
    "codebook_reshape = pd.read_csv(\"/Users/Avinash/Documents/Kanchanah/Springboard/Data_Science_Track/Capstone_Two_Other_Material/Opposite/codebook_reshape.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate the file to a format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape.drop(columns=['New','New_m'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape['New'] = codebook_reshape['Code / Range'].str.split('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape['New_m'] = codebook_reshape['New'].apply(lambda x: dict(zip(x[::2], x[1::2])))\n",
    "codebook_reshape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = dict(zip(codebook_reshape.Name,codebook_reshape.New_m))\n",
    "val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the variables in both files\n",
    "name = list(set(X_train_labeled_kmeans_mini_ori.columns).intersection(set(codebook_reshape.iloc[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the names of variables not in both files\n",
    "name_left = set(X_train_labeled_kmeans_mini_ori).difference(set(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the datasets\n",
    "X_train_labeled_kmeans_mini_done = pd.concat([X_train_labeled_kmeans_mini_ori[name].astype('int').astype('str'),X_train_labeled_kmeans_mini_ori[name_left],X_train_labeled_kmeans_mini[['type','predict','y_train']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_done.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_done.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit rows\n",
    "codebook_reshape_c = codebook_reshape[codebook_reshape['Name'].apply(lambda x: any([k in x for k in name]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_reshape_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict variables to loop\n",
    "val_label = dict(zip(codebook_reshape_c.Name,codebook_reshape_c.New_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in name:\n",
    "    X_train_labeled_kmeans_mini_done[var] = X_train_labeled_kmeans_mini_done[var].apply(lambda x: '{0:0>2}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode these variables\n",
    "pop = ['HBPPOPDN','HBRESDN']\n",
    "\n",
    "for var in pop:\n",
    "    X_train_labeled_kmeans_mini_done[var].replace({'01':'50','02':'300','03':'750','04':'1500','05':'3000','06':'7000','07':'17000','08':'30000'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels and make variables string\n",
    "for key, val in val_label.items():\n",
    "    X_train_labeled_kmeans_mini_done[key + \"_label\"] = X_train_labeled_kmeans_mini_done[key].replace(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some interesting variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will be easier to see in a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labeled_kmeans_mini_done.to_csv(\"X_train_labeled_kmeans_mini_done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['VEHOWNMO_label',\n",
    " 'HHFAMINC_label',\n",
    " 'HBRESDN_label',\n",
    " 'HBPPOPDN_label',\n",
    " 'EDUC_label',\n",
    " 'PRICE_label',\n",
    " 'CAR_label',\n",
    " 'PLACE_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Output, Input\n",
    "import plotly.express as px\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"Results from Clustering\"\n",
    "\n",
    "app.layout = html.Div(\n",
    "    children=[\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.P(children=\"\", className=\"header-emoji\"),\n",
    "                html.H1(\n",
    "                    children=\"Results from Clustering\", className=\"header-title\"\n",
    "                ),\n",
    "                html.P(\n",
    "                    children=\"The plots here show the results based on clustering for the National Household Travel Survey data\",\n",
    "                    className=\"header-description\",\n",
    "                ),\n",
    "            ],\n",
    "            className=\"header\",\n",
    "        ),\n",
    "        html.Div(\n",
    "        \n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        html.Div(children=\"cluster\", className=\"menu-title\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id=\"cluster-filter\",\n",
    "                            options=[\n",
    "                                {\"label\": cluster, \"value\": cluster}\n",
    "                                for cluster in X_train_labeled_kmeans_mini_done.type.unique()\n",
    "                            ],\n",
    "                            value=\"Kmeans\",\n",
    "                            clearable=False,\n",
    "                            searchable=False,\n",
    "                            className=\"dropdown\",\n",
    "                        ),\n",
    "                    ],\n",
    "                ),    \n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        html.Div(children=\"Variable\", className=\"menu-title\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id=\"variable-filter\",\n",
    "                            options=[{\"label\": van, \"value\": van}\n",
    "                            for van in name\n",
    "                            ],\n",
    "                            value=\"EDUC_label\",\n",
    "                            clearable=False,\n",
    "                            className=\"dropdown\",\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        html.Div(children=\"y_train\", className=\"menu-title\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id=\"ytrain-filter\",\n",
    "                            options=[\n",
    "                                {\"label\": avocado_type, \"value\": avocado_type}\n",
    "                                for avocado_type in X_train_labeled_kmeans_mini_done.predict.unique()\n",
    "                            ],\n",
    "                            value=\"1\",\n",
    "                            clearable=False,\n",
    "                            searchable=False,\n",
    "                            className=\"dropdown\",\n",
    "                        ),\n",
    "                    ],\n",
    "                ),\n",
    "                \n",
    "\n",
    "            ],\n",
    "            className=\"menu\",\n",
    "        ),\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=dcc.Graph(\n",
    "                        id=\"price-chart\",\n",
    "                        config={\"displayModeBar\": False},\n",
    "                    ),\n",
    "                    className=\"card\",\n",
    "                ),\n",
    "\n",
    "            ],\n",
    "            className=\"wrapper\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"price-chart\", \"figure\"),\n",
    "    [\n",
    "        Input(\"cluster-filter\", \"value\"),\n",
    "        Input(\"variable-filter\", \"value\"),\n",
    "        Input(\"ytrain-filter\", \"value\"),\n",
    "    ],\n",
    ")\n",
    "def update_charts(cluster, van, avocado_type):\n",
    "    \n",
    "    print(van)\n",
    "    \n",
    "    print(avocado_type)\n",
    "    \n",
    "    dat1 = X_train_labeled_kmeans_mini_done[X_train_labeled_kmeans_mini_done['type']==cluster]\n",
    "    \n",
    "    dat2 = dat1.groupby([van, \"y_train\"])[\"predict\"].value_counts().reset_index(name='count')\n",
    "    mask = ((dat2.y_train == avocado_type)\n",
    "    )\n",
    "    filtered_data = dat2.loc[mask, [van,\"predict\",\"count\"]]\n",
    "    \n",
    "    fig = px.bar(filtered_data, x=van, y=\"count\", \n",
    "                 color=\"predict\", barmode=\"group\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True,use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['y_train']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "px.bar(dat, x=\"CAR\", y=\"count\", color=\"y_train\", barmode = \"group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['y_train']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: None of the methods below work. Should we do PCA before performing the steps below?\n",
    "#I tried PCA but it did not help run the agglomerative clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_pca = pca.fit_transform(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_pca = pd.DataFrame(X_numeric_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = list(range(1,11))\n",
    "X_numeric_pca.columns = [\"C\" + str(num) for num in num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesn't work. Should I do a pca before running this clustering?\n",
    "agg_clustering = AgglomerativeClustering(n_clusters =2, affinity = 'euclidean', linkage='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering_label = agg_clustering.fit_predict(X_numeric_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Birch(threshold=0.01, n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#BIRCH_fit = model.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIRCH_fit.predict(X_train_numeric).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean Shift Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=SpectralClustering(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sc_fit = sc.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_fit.predict(X_train_numeric).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_cluster_id = sc_fit.predict(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
